{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepdreaming Multiple Caffe Models + Warping, Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Directions:\n",
    "1: Choose starting frame, name it frame00000.jpg, place file in framedir = '<i>dirname</i>' defined below. <br>\n",
    "2: Place goals file in base directory, or modify goals file location and place in framedir (see comments below). Define your parameters in goals file (these can be modified during the run) <br>\n",
    "3: Run the notebook after setting notebook parameters as well to generate frames. <br>\n",
    "4: Generate movie with 'ffmpeg -i frame%05d.jpg -vcodec libx264 -r <i>30</i> <i>movie-name.mp4</i>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import errno\n",
    "import subprocess\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import scipy\n",
    "import PIL.Image, PIL.ImageEnhance\n",
    "import caffe\n",
    "from cStringIO import StringIO\n",
    "from google.protobuf import text_format\n",
    "from IPython.display import clear_output, Image, display\n",
    "from skimage import transform, io, img_as_float, img_as_ubyte\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "caffe.set_mode_gpu()    # Comment out for CPU only\n",
    "caffe.set_device(0)     # Comment out for CPU only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Set</b> desired parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guided = \"True\"            # \"True\" or \"False\"\n",
    "blendoriginal = \"True\"     # Blend in the original frame? \"True\" or \"False\"\n",
    "bluramount = 0.3           # smaller = favors dream over original image during blending  ... 0 - 1\n",
    "s = 0.003                  # Zoom speed. Positive for inward / Negative for outward.\n",
    "width = 1024               # Frame width\n",
    "height = 683               # Frame height\n",
    "centerwidth = width / 2    # Center whirlpool based on chosen width\n",
    "centerheight = height / 2  # Center whirlpool based on chosen height\n",
    "octave_n=4                 # Otherwise defined in Goals file located in %framedir\n",
    "octave_scale=2.1           # Otherwise defined in Goals file located in %framedir\n",
    "clip=True  \n",
    "it = 1                     # n frames to blend between dreams\n",
    "mod = \"googlenet\" \n",
    "framedir = 'frames'        # Output frame directory\n",
    "frame_i = 0                # Current frame\n",
    "!rm -rf tmp && mkdir tmp   # Clear and Create tmp directory\n",
    "           # Model 1 path + files\n",
    "model_path_loc = '/usr/lib/python2.7/site-packages/caffe/models/bvlc_googlenet/'\n",
    "net_fn_loc     = 'deploy.prototxt'\n",
    "param_fn_loc   = 'bvlc_googlenet.caffemodel'\n",
    "           # Model 2 path + files\n",
    "model_path_loc = '/usr/lib/python2.7/site-packages/caffe/models/googlenet_places205/'\n",
    "net_fn_loc     = 'deploy_places205.protxt'\n",
    "param_fn_loc   = 'googlelet_places205_train_iter_2400000.caffemodel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run</b> the following to set up before the dream block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = \"frame%05d.jpg\"%frame_i                             # How to reach the current frame\n",
    "original = PIL.Image.open(\"%s/%s\"%(framedir,infile))         # Capture First frame from framedir for blending purposes\n",
    "PIL.Image.fromarray(np.uint8(original)).save(\"tmp/original.jpg\") # Save first frame for blending purposes\n",
    "\n",
    "logfile=\"log\"                                                # Define logfile name / location.  logfile=\"%s/log\"%framedir for log in framedir\n",
    "log = open(logfile, 'a')                                     # Logging functions below\n",
    "log.write(\"\\n\\nrestart %s\\n\\n\"%sys.argv[0])\n",
    "log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the Definitions!\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "def get_data():\n",
    "    goals = open(\"goals\", 'r')    # goals = open(\"%s/goals\"%framedir, 'r')   to place goals in framedir\n",
    "    line = goals.readline()\n",
    "    line.strip()\n",
    "    [t0, t1, t2, t3, eb, ec, es] = line.split()\n",
    "    v1 = [float(t0), float(t1), float(t2), float(t3), float(eb), float(ec), float(es)]\n",
    "    done = False\n",
    "    v2 = []\n",
    "    while not done:\n",
    "        line = goals.readline()\n",
    "        if line:\n",
    "            if line[0]=='#':\n",
    "                continue\n",
    "            else:\n",
    "                dat = line.split()\n",
    "                if len(dat)== 5:\n",
    "                    [a,b,c,d,e] = dat\n",
    "                    v2.append([a,b,int(c),int(d),float(e)])\n",
    "        else:\n",
    "            done=True\n",
    "    for j in v2:\n",
    "        goals.close()\n",
    "    return [v1,v2]\n",
    "\n",
    "def getnet(mod):\n",
    "    if mod == \"googlenet\":\n",
    "        model_path = model_path_loc\n",
    "        net_fn   = model_path + net_fn_loc\n",
    "        param_fn = model_path + param_fn_loc\n",
    "    elif mod == \"googlenet_places205\":\n",
    "        model_path = model_path_loc\n",
    "        net_fn   = model_path + net_fn_loc\n",
    "        param_fn = model_path + param_fn_loc\n",
    "    else:\n",
    "        abort(\"model not found\")\n",
    "    model = caffe.io.caffe_pb2.NetParameter()\n",
    "    text_format.Merge(open(net_fn).read(), model)\n",
    "    model.force_backward = True\n",
    "    open('tmp.prototxt', 'w').write(str(model))\n",
    "    return caffe.Classifier('tmp.prototxt', param_fn,\n",
    "                            mean = np.float32([104.0, 116.0, 122.0]), \n",
    "                            channel_swap = (2,1,0)) \n",
    "\n",
    "def preprocess(net, img):\n",
    "    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\n",
    "def deprocess(net, img):\n",
    "    return np.dstack((img + net.transformer.mean['data'])[::-1])\n",
    "\n",
    "def objective_L2(dst):\n",
    "    dst.diff[:] = dst.data \n",
    "\n",
    "def make_step(net, step_size=1.5, end='inception_4c/output', jitter=32, clip=True, objective=objective_L2):\n",
    "    '''Basic gradient ascent step.'''\n",
    "    src = net.blobs['data'] \n",
    "    dst = net.blobs[end]\n",
    "    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n",
    "    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2)\n",
    "    net.forward(end=end)\n",
    "    objective(dst)  \n",
    "    net.backward(start=end)\n",
    "    g = src.diff[0]\n",
    "    src.data[:] += step_size/np.abs(g).mean() * g\n",
    "    src.data[0] = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2)    \n",
    "    if clip:\n",
    "        bias = net.transformer.mean['data']\n",
    "        src.data[:] = np.clip(src.data, -bias, 255-bias)\n",
    "\n",
    "def deepdream(net, base_img, iter_n=10, octave_n=4, octave_scale=1.4, end=\"inception_4c/output\", clip=True, **step_params):\n",
    "    octaves = [preprocess(net, base_img)]\n",
    "    for i in xrange(octave_n-1):\n",
    "        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n",
    "    src = net.blobs['data']\n",
    "    detail = np.zeros_like(octaves[-1]) \n",
    "    for octave, octave_base in enumerate(octaves[::-1]):\n",
    "        h, w = octave_base.shape[-2:]\n",
    "        if octave > 0:\n",
    "            h1, w1 = detail.shape[-2:]\n",
    "            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n",
    "        src.reshape(1,3,h,w) \n",
    "        src.data[0] = octave_base+detail\n",
    "        for i in xrange(iter_n):\n",
    "            make_step(net, end=end, clip=clip, **step_params)\n",
    "            vis = deprocess(net, src.data[0])\n",
    "            if not clip: \n",
    "                vis = vis*(255.0/np.percentile(vis, 99.98))\n",
    "        detail = src.data[0]-octave_base\n",
    "    return deprocess(net, src.data[0])\n",
    "\n",
    "def fisheye(xy):\n",
    "    center = [centerwidth, centerheight]\n",
    "    xc, yc = (xy - center).T\n",
    "    r = np.sqrt(xc**2 + yc**2)\n",
    "    theta = np.arctan2(yc, xc)\n",
    "    rb = r*(1+np.exp(-r/t1)/t0)\n",
    "    shift = (np.exp(-(r/(t3))))*np.pi/t2\n",
    "    ret = np.column_stack((rb * np.cos(theta+shift), rb * np.sin(theta+shift))) + center\n",
    "    return ret\n",
    "    \n",
    "def objective_guide(dst):  \n",
    "    x = dst.data[0].copy()\n",
    "    y = guide_features\n",
    "    ch = x.shape[0]\n",
    "    x = x.reshape(ch,-1)\n",
    "    y = y.reshape(ch,-1)\n",
    "    A = x.T.dot(y)\n",
    "    dst.diff[0].reshape(ch,-1)[:] = y[:,A.argmax(1)]\n",
    "\n",
    "# Test data retrieval from goals file. If error, then define goals file in framedir\n",
    "print get_data()\n",
    "[[t0, t1, t2, t3, eb, ec, es], dd] = get_data()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define</b> guide images to loop through per frame if guided = \"True\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genguide = PIL.Image.open(\"tmp/original.jpg\")\n",
    "getguide = resizeimage.resize_width(genguide, 250)\n",
    "PIL.Image.fromarray(np.uint8(getguide)).save(\"tmp/newguide.jpg\") \n",
    "\n",
    "#guide_loop = ['tmp/newguide.jpg']  # Guide based on previous frame\n",
    "guide_loop = ['guideimages/1.png', 'guideimages/2.png', 'guideimages/3.png', 'guideimages/4.png', 'guideimages/5.png', 'guideimages/6.png', 'guideimages/7.png', 'guideimages/8.png', 'guideimages/9.png', 'guideimages/10.png', 'guideimages/11.png', 'guideimages/12.png', 'guideimages/13.png', 'guideimages/14.png', 'guideimages/15.png', 'guideimages/16.png', 'guideimages/17.png', 'guideimages/18.png', 'guideimages/19.png', 'guideimages/20.png', 'guideimages/21.png', 'guideimages/22.png', 'guideimages/23.png', 'guideimages/24.png', 'guideimages/25.png', 'guideimages/26.png', 'guideimages/27.png', 'guideimages/28.png', 'guideimages/29.png', 'guideimages/30.png', 'guideimages/31.png', 'guideimages/32.png', 'guideimages/33.png', 'guideimages/34.png', 'guideimages/35.png', 'guideimages/36.png', 'guideimages/37.png', 'guideimages/38.png', 'guideimages/39.png', 'guideimages/40.png', 'guideimages/41.png', 'guideimages/42.png', 'guideimages/43.png', 'guideimages/44.png', 'guideimages/45.png', 'guideimages/46.png', 'guideimages/47.png', 'guideimages/48.png', 'guideimages/49.png', 'guideimages/50.png', 'guideimages/51.png', 'guideimages/52.png', 'guideimages/53.png', 'guideimages/54.png', 'guideimages/55.png', 'guideimages/56.png', 'guideimages/57.png', 'guideimages/58.png', 'guideimages/59.png', 'guideimages/60.png', 'guideimages/61.png', 'guideimages/62.png', 'guideimages/63.png', 'guideimages/64.png', 'guideimages/65.png', 'guideimages/66.png', 'guideimages/67.png', 'guideimages/68.png', 'guideimages/69.png', 'guideimages/70.png', 'guideimages/71.png', 'guideimages/72.png', 'guideimages/73.png', 'guideimages/74.png', 'guideimages/75.png', 'guideimages/76.png', 'guideimages/77.png', 'guideimages/78.png', 'guideimages/79.png', 'guideimages/80.png', 'guideimages/81.png', 'guideimages/82.png', 'guideimages/83.png', 'guideimages/84.png', 'guideimages/85.png', 'guideimages/86.png', 'guideimages/87.png', 'guideimages/88.png', 'guideimages/89.png', 'guideimages/90.png', 'guideimages/91.png', 'guideimages/92.png', 'guideimages/93.png', 'guideimages/94.png', 'guideimages/95.png', 'guideimages/96.png', 'guideimages/97.png', 'guideimages/98.png', 'guideimages/99.png', 'guideimages/100.png', 'guideimages/101.png', 'guideimages/102.png', 'guideimages/103.png', 'guideimages/104.png', 'guideimages/105.png', 'guideimages/106.png', 'guideimages/107.png', 'guideimages/108.png', 'guideimages/109.png', 'guideimages/110.png', 'guideimages/111.png', 'guideimages/112.png', 'guideimages/113.png', 'guideimages/114.png', 'guideimages/115.png', 'guideimages/116.png', 'guideimages/117.png', 'guideimages/118.png', 'guideimages/119.png', 'guideimages/120.png', 'guideimages/121.png', 'guideimages/122.png', 'guideimages/123.png', 'guideimages/124.png', 'guideimages/125.png', 'guideimages/126.png', 'guideimages/127.png', 'guideimages/128.png', 'guideimages/129.png', 'guideimages/130.png', 'guideimages/131.png', 'guideimages/132.png', 'guideimages/133.png', 'guideimages/134.png', 'guideimages/135.png', 'guideimages/136.png', 'guideimages/137.png', 'guideimages/138.png', 'guideimages/139.png', 'guideimages/140.png', 'guideimages/141.png', 'guideimages/142.png', 'guideimages/143.png', 'guideimages/144.png', 'guideimages/145.png', 'guideimages/146.png', 'guideimages/147.png', 'guideimages/148.png', 'guideimages/149.png', 'guideimages/150.png', 'guideimages/151.png', 'guideimages/152.png', 'guideimages/153.png', 'guideimages/154.png', 'guideimages/155.png', 'guideimages/156.png', 'guideimages/157.png', 'guideimages/158.png', 'guideimages/159.png', 'guideimages/160.png', 'guideimages/161.png', 'guideimages/162.png', 'guideimages/163.png', 'guideimages/164.png', 'guideimages/165.png', 'guideimages/166.png', 'guideimages/167.png', 'guideimages/168.png', 'guideimages/169.png', 'guideimages/170.png', 'guideimages/171.png', 'guideimages/172.png', 'guideimages/173.png', 'guideimages/174.png', 'guideimages/175.png', 'guideimages/176.png', 'guideimages/177.png', 'guideimages/178.png', 'guideimages/179.png', 'guideimages/180.png', 'guideimages/181.png', 'guideimages/182.png', 'guideimages/183.png', 'guideimages/184.png', 'guideimages/185.png', 'guideimages/186.png', 'guideimages/187.png', 'guideimages/188.png', 'guideimages/189.png', 'guideimages/190.png', 'guideimages/191.png', 'guideimages/192.png', 'guideimages/193.png', 'guideimages/194.png', 'guideimages/195.png', 'guideimages/196.png', 'guideimages/197.png', 'guideimages/198.png', 'guideimages/199.png', 'guideimages/200.png', 'guideimages/201.png', 'guideimages/202.png', 'guideimages/203.png', 'guideimages/204.png', 'guideimages/205.png', 'guideimages/206.png', 'guideimages/207.png', 'guideimages/208.png', 'guideimages/209.png', 'guideimages/210.png']\n",
    "guide = np.float32(PIL.Image.open(guide_loop[frame_i % len (guide_loop)]))  # Loop through guide images determined by current frame_i number.\n",
    "print guide_loop[frame_i % len (guide_loop)]                                # Show currently selected guide image based on current frame_i number.\n",
    "showarray(guide)                                                            # Shows guide image selected for the frame number: frame_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dream Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = io.imread(\"%s/%s\"%(framedir,infile))\n",
    "frame_i += 1\n",
    "old = new\n",
    "\n",
    "net = getnet(\"googlenet\")\n",
    "net1 = getnet(\"googlenet_places205\")\n",
    "new = old\n",
    "\n",
    "h, w = (height, width)\n",
    "box = (0, 0, width, height)\n",
    "\n",
    "for i in xrange(10000):\n",
    "    new = nd.affine_transform(new, [1-s,1-s,1], [h*s/2,w*s/2,0], order=1)\n",
    "    PIL.Image.fromarray(np.uint8(new)).save(\"tmp/temp.jpg\")  \n",
    "    newguide = PIL.Image.open(\"tmp/temp.jpg\")\n",
    "    newg = resizeimage.resize_width(newguide, 250)\n",
    "    PIL.Image.fromarray(np.uint8(newg)).save(\"tmp/newguide.jpg\")  \n",
    "    if blendoriginal == \"True\":\n",
    "        new = PIL.Image.blend(PIL.Image.fromarray(np.uint8(new)), PIL.Image.open(\"tmp/original.jpg\"), bluramount)\n",
    "    new = img_as_ubyte(new)\n",
    "    new = transform.warp(new, fisheye)\n",
    "    new = img_as_ubyte(new)\n",
    "    old = img_as_ubyte(old)\n",
    "    old = transform.warp(old, fisheye)\n",
    "    old = img_as_ubyte(old)\n",
    "    nim = PIL.Image.fromarray(np.uint8(new))\n",
    "    oim = PIL.Image.fromarray(np.uint8(old))\n",
    "    bp = (frame_i%it+0.)/(it)\n",
    "    out = PIL.Image.blend(oim, nim, bp)\n",
    "    out.save(\"%s/frame%05d.jpg\"%(framedir, frame_i))\n",
    "    frame_i += 1\n",
    "    if frame_i%it==0:\n",
    "        log.write(\"\\nframe%05d:\\n\"%frame_i)\n",
    "        [[t0, t1, t2, t3, eb, ec, es], dd] = get_data()\n",
    "        log.write(\"%s %s %s %s %s %s %s\\n\"%(t0,t1,t2,t3,eb,ec,es))\n",
    "        old = new\n",
    "        for [end, mod, iter_n, octave_n, octave_scale] in dd:\n",
    "            log.write(\"%s %s %s %s %s\\n\"%(end, mod, iter_n, octave_n, octave_scale))\n",
    "            log.flush()\n",
    "            if guided == \"False\":\n",
    "                if mod == \"googlenet\":\n",
    "                    new = deepdream(net, new, end=end, iter_n=iter_n, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                elif mod == \"googlenet_places205\":\n",
    "                    new = deepdream(net1, new, end=end, iter_n=iter_n, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                elif mod == \"both\":\n",
    "                    new = deepdream(net, new, end=end, iter_n=iter_n, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                    new = deepdream(net1, new, end=end, iter_n=iter_n, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                else:\n",
    "                    print \"error: %s not recognized\"%mod\n",
    "                    log.write(\"error: %s not recognized\\n\"%mod)\n",
    "            elif guided == \"True\":\n",
    "                if mod == \"googlenet\":\n",
    "                    h, w = guide.shape[:2]\n",
    "                    src, dst = net.blobs['data'], net.blobs[end]\n",
    "                    src.reshape(1,3,h,w)\n",
    "                    src.data[0] = preprocess(net, guide)\n",
    "                    net.forward(end=end)\n",
    "                    guide_features = dst.data[0].copy()\n",
    "                    new = deepdream(net, new, end=end, iter_n=iter_n, objective=objective_guide, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                elif mod == \"googlenet_places205\":\n",
    "                    h, w = guide.shape[:2]\n",
    "                    src, dst = net.blobs['data'], net.blobs[end]\n",
    "                    src.reshape(1,3,h,w)\n",
    "                    src.data[0] = preprocess(net, guide)\n",
    "                    net.forward(end=end)\n",
    "                    guide_features = dst.data[0].copy()\n",
    "                    new = deepdream(net1, new, end=end, iter_n=iter_n, objective=objective_guide, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                elif mod == \"both\":\n",
    "                    h, w = guide.shape[:2]\n",
    "                    src, dst = net.blobs['data'], net.blobs[end]\n",
    "                    src.reshape(1,3,h,w)\n",
    "                    src.data[0] = preprocess(net, guide)\n",
    "                    net.forward(end=end)\n",
    "                    guide_features = dst.data[0].copy()\n",
    "                    new = deepdream(net, new, end=end, iter_n=iter_n, objective=objective_guide, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                    new = deepdream(net1, new, end=end, iter_n=iter_n, objective=objective_guide, octave_n=octave_n, octave_scale=octave_scale)\n",
    "                else:\n",
    "                    print \"error: %s not recognized\"%mod\n",
    "                    log.write(\"error: %s not recognized\\n\"%mod)\n",
    "            else:\n",
    "                print \"set guided = 'True' or... guided = 'False'\"\n",
    "                log.write(\"error: guide = 'True' or 'False' not set\")\n",
    "        new = PIL.Image.fromarray(np.uint8(new))\n",
    "        new = PIL.ImageEnhance.Brightness(new).enhance(eb)\n",
    "        new = PIL.ImageEnhance.Contrast(new).enhance(ec)\n",
    "        new = img_as_ubyte(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Generate</b> your video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i frames/frame%05d.jpg -vcodec libx264 -r 60 dream.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
